{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee \n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "\n",
    "from geeml.utils import eeprint\n",
    "import geemap\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = ee.Date('2017-03-28')\n",
    "mtbs = ee.FeatureCollection(\"USFS/GTAC/MTBS/burned_area_boundaries/v1\")\\\n",
    "    .filter(ee.Filter.gte('Ig_Date', startDate.millis()))\n",
    "mtbs_sz = 5613#mtbs.size().getInfo()#7583 L8\n",
    "print(mtbs_sz)\n",
    "mtbs_list = mtbs.toList(mtbs_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeprint(mtbs.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map =geemap.Map()\n",
    "Map.addLayer(test)\n",
    "Map.addLayer(fired)\n",
    "Map.centerObject(test, 13)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landsat data exploration\n",
    "def cloudMask1(image):\n",
    "    clouds = image.select('QA_PIXEL').bitwiseAnd(0b1000).eq(0)\n",
    "    cirrus = image.select('QA_PIXEL').bitwiseAnd(0b1100).eq(0)\n",
    "    saturationMask = image.select('QA_RADSAT').eq(0)\n",
    "\n",
    "    #  Replace the original bands with the scaled ones and apply the masks.\n",
    "    return image\\\n",
    "        .updateMask(clouds)\\\n",
    "        .updateMask(cirrus)\\\n",
    "        .updateMask(saturationMask)\n",
    "\n",
    "def cloudMask2(image):\n",
    "    clouds = image.select('QA_PIXEL').bitwiseAnd(0b1000).eq(0)\n",
    "    cirrus = image.select('QA_PIXEL').bitwiseAnd(0b1100).eq(0)\n",
    "    saturationMask = image.select('QA_RADSAT').eq(0)\n",
    "\n",
    "    #   Apply the scaling factors to the appropriate bands.\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "\n",
    "    # Compute normalised burn ratio (NBR)\n",
    "    nbr = image.normalizedDifference(['SR_B5', 'SR_B7']).multiply(-1).rename('nbr')\n",
    "\n",
    "    #  Replace the original bands with the scaled ones and apply the masks.\n",
    "    return opticalBands.addBands([nbr], None, True)\\\n",
    "        .updateMask(clouds)\\\n",
    "        .updateMask(cirrus)\\\n",
    "        .updateMask(saturationMask)\n",
    "def qualityMosaicPercentile(collection, QAband, percentile):\n",
    "    # Compute percentile image\n",
    "    percentileImage = collection.select(QAband).reduce(ee.Reducer.percentile([percentile]))\n",
    "    #  Compute distance of every pixel from the computed percentile in that location\n",
    "    withDist = ee.ImageCollection(collection.map(lambda image: image.addBands([\n",
    "        image.select(QAband).subtract(percentileImage).abs().multiply(-1).rename('quality')])))\n",
    "    return withDist.qualityMosaic('quality')\n",
    "\n",
    "# Given a fire event get pre and post fire image from single sensor \n",
    "eventDate = ee.Date(event.getNumber('Ig_Date'))\n",
    "print('event Date:', eventDate.format().getInfo())\n",
    "dateBuffer = 10\n",
    "# get first image after fire\n",
    "startDate = eventDate#.advance(1, 'week')\n",
    "endDate = eventDate.advance(dateBuffer, 'week')\n",
    "sat_data = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\").filterBounds(event.geometry()).filterDate(startDate, endDate)\n",
    "postFireImg2 = qualityMosaicPercentile(sat_data.map(cloudMask2), 'nbr', 75)\n",
    "postFireImg1 = sat_data.map(cloudMask1).sort('system:time_start', False).reduce(ee.Reducer.firstNonNull())#.first()\n",
    "\n",
    "# get first image before fire\n",
    "startDate = eventDate.advance(dateBuffer*-1, 'week')\n",
    "endDate = eventDate\n",
    "preFireImg = sat_data.filterBounds(event.geometry()).filterDate(startDate, endDate).sort('system:time_start', False).first()\n",
    "# print('preFire Date:', ee.Date(preFireImg.date()).format().getInfo())\n",
    "\n",
    "# Visualise images\n",
    "Map.addLayer(postFireImg2.select('SR_B.*'), {'min':0, 'max':0.7, 'bands': ['SR_B7', 'SR_B5', 'SR_B4']}, 'Post2')\n",
    "\n",
    "Map.addLayer(postFireImg1.select('SR_B.*').multiply(0.0000275).add(-0.2), {'min':0, 'max':0.7, 'bands': ['SR_B7_first', 'SR_B5_first', 'SR_B4_first']}, 'Post1')\n",
    "# Map.addLayer(preFireImg.select('SR_B.').multiply(0.0000275).add(-0.2), {'min':0, 'max':0.7, 'bands': ['SR_B7', 'SR_B5', 'SR_B4']}, 'Pre')\n",
    "\n",
    "Map.addLayer(event.geometry())\n",
    "Map.centerObject(event.geometry(), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessOptical(image, sensor):\n",
    "    \"\"\"Select Bands and scale between 0 and 1\n",
    "    \"\"\"\n",
    "    bandSelect = {'Sentinel-2': 'B.*',\n",
    "                    'LANDSAT_8': 'SR_B.',\n",
    "                    'LANDSAT_9': 'SR_B.'}\n",
    "    # Step 2) radiometric correction\n",
    "    radiometricMultiplySelect = {'Sentinel-2': 0.0001,\n",
    "                    'LANDSAT_8': 0.0000275,\n",
    "                    'LANDSAT_9': 0.0000275}\n",
    "    radiometricAddSelect = {'Sentinel-2': 0,\n",
    "                    'LANDSAT_8': -0.2,\n",
    "                    'LANDSAT_9': -0.2}\n",
    "    \n",
    "    # Step 3) depending on image selected, select cloud band\n",
    "    return image.select(bandSelect.get(sensor)).multiply(radiometricMultiplySelect.get(sensor)).add(radiometricAddSelect.get(sensor)).copyProperties(image)\n",
    "\n",
    "# Sentinel-2 data exploration\n",
    "def cloudMask1(imageCollection):\n",
    "    #  Cloud Score+ image collection. Note Cloud Score+ is produced from Sentinel-2\n",
    "        # Level 1C data and can be applied to either L1C or L2A collections.\n",
    "        csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED')\n",
    "\n",
    "        #  Use 'cs' or 'cs_cdf', depending on your use-case; see docs for guidance.\n",
    "        QA_BAND = 'cs'\n",
    "\n",
    "        # The threshold for masking; values between 0.50 and 0.65 generally work well.\n",
    "        # Higher values will remove thin clouds, haze & cirrus shadows.\n",
    "        CLEAR_THRESHOLD = 0.6\n",
    "\n",
    "        # link Sentinel-2 image with corresponding Cloud Score+\n",
    "        cloudMask = imageCollection.linkCollection(csPlus, [QA_BAND]).map(lambda img:\n",
    "            img.updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD)).select('B.*').divide(10000))\n",
    "\n",
    "        # scale and mask out clouds\n",
    "        return cloudMask\n",
    "\n",
    "def cloudMask2(imageCollection):\n",
    "        #  Cloud Score+ image collection. Note Cloud Score+ is produced from Sentinel-2\n",
    "        # Level 1C data and can be applied to either L1C or L2A collections.\n",
    "        csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED')\n",
    "\n",
    "        #  Use 'cs' or 'cs_cdf', depending on your use-case; see docs for guidance.\n",
    "        QA_BAND = 'cs'\n",
    "\n",
    "        # The threshold for masking; values between 0.50 and 0.65 generally work well.\n",
    "        # Higher values will remove thin clouds, haze & cirrus shadows.\n",
    "        CLEAR_THRESHOLD = 0.6\n",
    "        \n",
    "        # radiometric correction and band selection\n",
    "        # preProcessCollection = imageCollection.map(lambda image: preprocessOptical(image, 'Sentinel-2'))\n",
    "        # link Sentinel-2 image with corresponding Cloud Score+\n",
    "        # cloudMask = imageCollection.linkCollection(csPlus, [QA_BAND]).map(lambda img:\n",
    "        #     img.addBands(img.normalizedDifference(['B8', 'B12']).multiply(10000).rename('nbr'))\\\n",
    "        #         .updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD)).select(['B.*', 'nbr']).divide(10000)\n",
    "        #     )\n",
    "        cloudMask = imageCollection.linkCollection(csPlus, [QA_BAND]).map(lambda img:\n",
    "            img.select(['B.*'])\\\n",
    "                .updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD)).divide(10000)\\\n",
    "                    .addBands(img.normalizedDifference(['B8A', 'B12']).rename('nbr'))\n",
    "            )\n",
    "            \n",
    "        # scale and mask out clouds\n",
    "        return cloudMask\n",
    "\n",
    "def qualityMosaicPercentile(collection, QAband, percentile):\n",
    "    # Compute percentile image\n",
    "    percentileImage = collection.select(QAband).reduce(ee.Reducer.percentile([percentile]))\n",
    "    #  Compute distance of every pixel from the computed percentile in that location\n",
    "    withDist = ee.ImageCollection(collection.map(lambda image: image.addBands([\n",
    "        image.select(QAband).subtract(percentileImage).abs().multiply(-1).rename('quality')])))\n",
    "    return withDist.qualityMosaic('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = ee.Feature(mtbs_list.get(5))\n",
    "# Given a fire event get pre and post fire image from single sensor \n",
    "eventDate = ee.Date(event.getNumber('Ig_Date'))\n",
    "# print('event Date:', eventDate.format().getInfo())\n",
    "\n",
    "dateBuffer = 15\n",
    "# get first image before fire\n",
    "startDate = eventDate.advance(dateBuffer*-1, 'week')\n",
    "endDate = eventDate\n",
    "\n",
    "sat_data = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\").filterBounds(event.geometry())\n",
    "\n",
    "preFireImg = sat_data.filterDate(startDate, endDate).sort('system:time_start', False).first()\n",
    "prenbr = preFireImg.normalizedDifference(['B8A', 'B12']).rename('nbr')\n",
    "# print('preFire Date:', ee.Date(preFireImg.date()).format().getInfo())\n",
    "\n",
    "# get first image after fire\n",
    "startDate = eventDate#.advance(1, 'week')\n",
    "endDate = eventDate.advance(dateBuffer, 'week')\n",
    "postFireImg2 = qualityMosaicPercentile(cloudMask2(sat_data.filterDate(startDate, endDate)).map(lambda img: img.addBands(prenbr.subtract(img.normalizedDifference(['B8A', 'B12'])).rename('dnbr'))), 'dnbr', 90)\n",
    "postFireImg1 = cloudMask1(sat_data.filterDate(startDate, endDate)).sort('system:time_start', False).reduce(ee.Reducer.firstNonNull())#.first()\n",
    "\n",
    "# Visualise images\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(postFireImg2, {'min':0, 'max':0.7, 'bands': ['B12', 'B8A', 'B4']}, 'Post2')\n",
    "\n",
    "Map.addLayer(postFireImg1, {'min':0, 'max':0.7, 'bands': ['B12_first', 'B8A_first', 'B4_first']}, 'Post1')\n",
    "# Map.addLayer(preFireImg.select('SR_B.').multiply(0.0000275).add(-0.2), {'min':0, 'max':0.7, 'bands': ['SR_B7', 'SR_B5', 'SR_B4']}, 'Pre')\n",
    "\n",
    "Map.addLayer(event.geometry())\n",
    "Map.centerObject(event.geometry(), 8)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supportedSensors = {'Sentinel-1': ee.ImageCollection('COPERNICUS/S1_GRD'),\n",
    "                    'Sentinel-2': ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\"),\n",
    "                    'LANDSAT_8': ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\"),\n",
    "                    'LANDSAT_9': ee.ImageCollection(\"LANDSAT/LC09/C02/T1_L2\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Union\n",
    "from geedim.download import BaseImage\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "MODULE_FULL_PATH = r'C:\\Users\\coach\\myfiles\\python_modules'\n",
    "\n",
    "sys.path.insert(1, MODULE_FULL_PATH)\n",
    "import wrapper as wp #https://github.com/adugnag/gee_s1_ard\n",
    "\n",
    "### Citation\n",
    "# Mullissa, A.; Vollrath, A.; Odongo-Braun, C.; Slagter, B.; Balling, J.; Gou, Y.; Gorelick, N.;\n",
    "# Reiche, J. Sentinel-1 SAR Backscatter Analysis Ready Data Preparation in Google Earth Engine.\n",
    "# Remote Sens. 2021, 13, 1954. https://doi.org/10.3390/rs13101954\n",
    "\n",
    "parameters = {#1. Data Selection\n",
    "              'START_DATE': \"2020-01-01\",\n",
    "              'STOP_DATE': \"2020-03-31\",\n",
    "              'POLARIZATION':'VVVH',\n",
    "              'PLATFORM_NUMBER': ['A','B'],\n",
    "              'ORBIT' : 'BOTH',\n",
    "              'ORBIT_NUM': None,\n",
    "              'ROI': None, \n",
    "              #2. Additional Border noise correction\n",
    "              'APPLY_BORDER_NOISE_CORRECTION': True,\n",
    "              #3.Speckle filter\n",
    "              'APPLY_SPECKLE_FILTERING': True,\n",
    "              'SPECKLE_FILTER_FRAMEWORK': 'MONO',\n",
    "              'SPECKLE_FILTER': 'REFINED LEE',\n",
    "              'SPECKLE_FILTER_KERNEL_SIZE': 9,\n",
    "              'SPECKLE_FILTER_NR_OF_IMAGES': 10,\n",
    "              #4. Radiometric terrain normalization\n",
    "              'APPLY_TERRAIN_FLATTENING': True,\n",
    "              'DEM': ee.ImageCollection(\"projects/sat-io/open-datasets/GLO-30\").mosaic(),\n",
    "              'TERRAIN_FLATTENING_MODEL': 'VOLUME',\n",
    "              'TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER': 0,\n",
    "              #5. Output\n",
    "              'FORMAT' : 'DB',\n",
    "              'CLIP_TO_ROI': False,\n",
    "              'SAVE_ASSET': False,\n",
    "              'ASSET_ID':None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(sensor, pre, event, dateBuffer):\n",
    "    \"\"\"\n",
    "    Get the temporally closest pre-fire and post-fire optical or radar images after preprocessing both\n",
    "     the optical images.\n",
    "\n",
    "    Args:\n",
    "        event (ee.Feature): A fire event delineating the boundary of burnt area\n",
    "        dateBuffer (int): The temporal window to locate a relevant image. In units of weeks.\n",
    "\n",
    "    Returns:\n",
    "        A pre-fire and post-fire optical or radar image\n",
    "    \"\"\"\n",
    "    # Filter images that intersect the geometry using the optimised filterBounds. Thereafter, use the\n",
    "    # ee.filter.contains that is not as optimised as filterBounds\n",
    "    images = supportedSensors.get(sensor).filterBounds(event.geometry())\n",
    "    eventDate = ee.Date(event.get('Ig_Date'))\n",
    "    if pre:\n",
    "        startDate = eventDate.advance(dateBuffer*-1, 'week')\n",
    "        endDate = eventDate\n",
    "        outImage = cloudMask1(images.filterDate(startDate, endDate).sort('system:time_start', False)).reduce(ee.Reducer.firstNonNull()).regexpRename('.{6}$','')\n",
    "        # .filter(ee.Filter.contains('.geo', event.geometry())).sort('system:time_start', False).first()\n",
    "  \n",
    "    else:\n",
    "        # postfire\n",
    "        startDate = eventDate\n",
    "        endDate = eventDate.advance(dateBuffer, 'week')\n",
    "        outImage = cloudMask2(images.filterDate(startDate, endDate))#.reduce(ee.Reducer.firstNonNull()).regexpRename('.{6}$','')#.qualityMosaic('nbr')\n",
    "        # .filter(ee.Filter.contains('.geo', event.geometry())).sort('system:time_start', True).first()\n",
    "    \n",
    "    return outImage\n",
    "\n",
    "    # Given a fire event get pre and post fire image from multi-sensors\n",
    "def getOpticalRadarPairs(sensor:str, dnbr:bool, event: ee.Feature, dateBuffer: int = 4)-> ee.Image:\n",
    "    \"\"\"\n",
    "     Get optical-radar pairs for a given fire event. First image after fire event and image before fire event\n",
    "\n",
    "     Args:\n",
    "        sensor(str): The name of the sensor. One of ['Sentinel-1', 'Sentinel-2', 'Landsat_8', 'Landsat_9']\n",
    "        event(ee.Feature): A fire event\n",
    "        dateBuffer(int): The temporal-search window. \n",
    "    \n",
    "    Returns:\n",
    "        An image with optical-radar pairs\n",
    "\n",
    "    \"\"\"\n",
    "    # Post-fire image\n",
    "    if sensor != 'any':\n",
    "        postOpticalImage = getImage(sensor, False, event, dateBuffer= dateBuffer)\n",
    "    else:\n",
    "        s2post = getImage('Sentinel-2', False, event, dateBuffer= dateBuffer)\n",
    "        l8post = getImage('LANDSAT_8', False, event, dateBuffer= dateBuffer)\n",
    "        l9post = getImage('LANDSAT_9', False, event, dateBuffer= dateBuffer)\n",
    "        # get the earliest optical image (between L8, L9 and S2) that was captured after the fire event\n",
    "        postOpticalImage = ee.ImageCollection.fromImages([s2post, l8post, l9post]).sort('system:time_start', True).first()\n",
    "    # pre-process post-fire image\n",
    "    # postOpticalImage = ee.Image(preprocessOptical(postOpticalImage, sensor).copyProperties(postOpticalImage))\n",
    "\n",
    "    # if sensor == 'Sentinel-1':\n",
    "    #     # RADAR\n",
    "    #     s1post = getImage('Sentinel-1', False, event, dateBuffer= dateBuffer)\n",
    "    #     # preprocess pre-fire radar image\n",
    "    #     parameters.update({'STOP_DATE': s1post.date().advance(1, 'day'), 'START_DATE': s1post.date(), 'ROI': event.geometry()})\n",
    "    #     s1post = wp.s1_preproc(parameters).select('V.')\n",
    "    \n",
    "    # pre-fire\n",
    "    if sensor != 'any':\n",
    "        # If only one sensor is to be used\n",
    "        preOpticalImage = getImage(sensor, True, event, dateBuffer= dateBuffer)\n",
    "    else:\n",
    "        # If any optical sensor is to be used\n",
    "        s2pre = getImage('Sentinel-2', True, event, dateBuffer= dateBuffer)\n",
    "        l8pre = getImage('LANDSAT_8', True, event, dateBuffer= dateBuffer)\n",
    "        l9pre = getImage('LANDSAT_9', True, event, dateBuffer= dateBuffer)\n",
    "        # get the earliest optical image (between L8, L9 and S2) that was captured after the fire event\n",
    "        preOpticalImage = ee.ImageCollection.fromImages([s2pre, l8pre, l9pre]).sort('system:time_start', True).first()\n",
    "    \n",
    "    # elif multisensor:\n",
    "    #     # if multisensor data is to be used, add radar to optical\n",
    "    #     # RADAR\n",
    "    #     s1pre = getImage('Sentinel-1', True, event, dateBuffer= dateBuffer)\n",
    "    #     # preprocess pre-fire radar image\n",
    "    #     parameters.update({'STOP_DATE': s1pre.date().advance(1, 'day'), 'START_DATE': s1pre.date(), 'ROI': event.geometry()})\n",
    "    #     s1pre = wp.s1_preproc(parameters).select('V.')\n",
    "\n",
    "    # pre-process pre-fire image\n",
    "    # preOpticalImage = ee.Image(preprocessOptical(preOpticalImage, sensor).copyProperties(preOpticalImage))\n",
    "\n",
    "    if dnbr:\n",
    "        postOpticalImage = qualityMosaicPercentile(postOpticalImage.map(lambda img: img.addBands(\n",
    "            preOpticalImage.normalizedDifference(['B8A', 'B12']).subtract(img.normalizedDifference(['B8A', 'B12'])).rename('dnbr'))), 'dnbr', 95) \n",
    "    \n",
    "    return postOpticalImage\n",
    "    # return preOpticalImage.regexpRename('$', '_pre'), s1pre, postOpticalImage.regexpRename('$', '_post'), s1post\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a fire event get pre and post fire image from multi-sensors\n",
    "def getOpticalRadarPairs(event: ee.Feature, dateBuffer: int = 4)-> Union[ee.Image, ee.Image, ee.Image, ee.Image]:\n",
    "    \"\"\"\n",
    "    Get the temporally closest pre-fire and post-fire radar and optical image pairs after preprocessing both\n",
    "     the radar and optical images.\n",
    "\n",
    "    Args:\n",
    "        event (ee.Feature): A fire event delineating the boundary of burnt area\n",
    "        dateBuffer (int): The temporal window to locate a relevant image. In units of weeks.\n",
    "\n",
    "    Returns:\n",
    "        Four images, a pre-fire and post-fire optical-radar image pair\n",
    "    \"\"\"\n",
    "    eventDate = ee.Date(event.getNumber('Ig_Date'))\n",
    "    # postfire\n",
    "    startDate = eventDate\n",
    "    endDate = eventDate.advance(dateBuffer, 'week')\n",
    "    s1 = ee.ImageCollection('COPERNICUS/S1_GRD').filterBounds(event.geometry())\n",
    "    s2 = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\").filterBounds(event.geometry())\n",
    "    l8 = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\").filterBounds(event.geometry())\n",
    "    l9 = ee.ImageCollection(\"LANDSAT/LC09/C02/T1_L2\").filterBounds(event.geometry())\n",
    "    s2post = s2.filterDate(startDate, endDate).sort('system:time_start', True).first()\n",
    "    l8post = l8.filterDate(startDate, endDate).sort('system:time_start', True).first()\n",
    "    l9post = l9.filterDate(startDate, endDate).sort('system:time_start', True).first()\n",
    "    # get the earliest optical image (between L8, L9 and S2) that was captured after the fire event\n",
    "    postOpticalImage = ee.ImageCollection.fromImages([s2post, l8post, l9post]).sort('system:time_start', True).first()\n",
    "    # pre-process post-fire image\n",
    "    postOpticalImage = preprocessOptical(postOpticalImage)\n",
    "    \n",
    "    # RADAR\n",
    "    s1post = s1.filterDate(startDate, endDate).sort('system:time_start', True).first()\n",
    "    # preprocess pre-fire radar image\n",
    "    parameters.update({'STOP_DATE': s1post.date().advance(1, 'day'), 'START_DATE': s1post.date(), 'ROI': event.geometry()})\n",
    "    s1post = wp.s1_preproc(parameters).select('V.')\n",
    "    \n",
    "    # pre-fire\n",
    "    startDate = eventDate.advance(dateBuffer*-1, 'week')\n",
    "    endDate = eventDate\n",
    "    s2pre = s2.filterDate(startDate, endDate).sort('system:time_start', False).first()\n",
    "    l8pre = l8.filterDate(startDate, endDate).sort('system:time_start', False).first()\n",
    "    l9pre = l9.filterDate(startDate, endDate).sort('system:time_start', False).first()\n",
    "    # get the optical image (between L8, L9 and S2) that was captured before the fire event\n",
    "    preOpticalImage = ee.ImageCollection.fromImages([s2pre, l8pre, l9pre]).sort('system:time_start', True).first()\n",
    "    # pre-process post-fire image\n",
    "    preOpticalImage = preprocessOptical(preOpticalImage)\n",
    "\n",
    "    #RADAR\n",
    "    s1pre = s1.filterDate(startDate, endDate).sort('system:time_start', False).first()\n",
    "    # preprocess post-fire radar image\n",
    "    parameters.update({'STOP_DATE': s1pre.date().advance(1, 'day'), 'START_DATE': s1pre.date(), 'ROI': event.geometry()})\n",
    "    s1pre = wp.s1_preproc(parameters).select('V.')\n",
    "    return preOpticalImage.regexpRename('$', '_pre'), s1pre, postOpticalImage.regexpRename('$', '_post'), s1post\n",
    "\n",
    "def preprocessOptical(image):\n",
    "    # Get optical sensor name\n",
    "    sensor = image.get('SPACECRAFT_ID').getInfo()\n",
    "    if sensor is None:\n",
    "        sensor = 'Sentinel-2'\n",
    "    # Step 1) select useful bands\n",
    "    bandSelect = {'Sentinel-2': 'B.*',\n",
    "                    'LANDSAT_8': 'SR_B.',\n",
    "                    'LANDSAT_9': 'SR_B.'}\n",
    "    # Step 2) radiometric correction\n",
    "    radiometricMultiplySelect = {'Sentinel-2': 0.0001,\n",
    "                    'LANDSAT_8': 0.0000275,\n",
    "                    'LANDSAT_9': 0.0000275}\n",
    "    radiometricAddSelect = {'Sentinel-2': 0,\n",
    "                    'LANDSAT_8': -0.2,\n",
    "                    'LANDSAT_9': -0.2}\n",
    "    \n",
    "    # Step 3) depending on image selected, select cloud band\n",
    "    return image.select(bandSelect.get(sensor)).multiply(radiometricMultiplySelect.get(sensor)).add(radiometricAddSelect.get(sensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareLabel(event: ee.Feature, patchSize: int, scale: int)-> ee.Image:\n",
    "    \"\"\"\n",
    "    Converts a burn area polygon (ee.Feature) to a raster label. Burnt pixels are assigned a value of 1.\n",
    "    Unburnt pixels are assigned a value of 0. the returned ee.Image dimensions should closely approximate\n",
    "    the number of pixels divisible by the patchSize.\n",
    "\n",
    "    Args:\n",
    "        event(ee.Feature): The delineated burn area polygon to rasterize.\n",
    "        patchSize (int): The desirable patch dimension when training the DNN model.\n",
    "        scale (int): The desired output scale for the label.\n",
    "\n",
    "    Returns:\n",
    "        The rasterised label (ee.Image)\n",
    "    \"\"\"\n",
    "    # Define the WKT string for EPSG:102005\n",
    "    wkt = ('PROJCS[\"USA_Contiguous_Equidistant_Conic\",'\n",
    "        'GEOGCS[\"GCS_North_American_1983\",'\n",
    "        'DATUM[\"D_North_American_1983\",'\n",
    "        'SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],'\n",
    "        'PRIMEM[\"Greenwich\",0.0],'\n",
    "        'UNIT[\"Degree\",0.0174532925199433]],'\n",
    "        'PROJECTION[\"Equidistant_Conic\"],'\n",
    "        'PARAMETER[\"False_Easting\",0.0],'\n",
    "        'PARAMETER[\"False_Northing\",0.0],'\n",
    "        'PARAMETER[\"longitude_of_center\",-96.0],'\n",
    "        'PARAMETER[\"Standard_Parallel_1\",33.0],'\n",
    "        'PARAMETER[\"Standard_Parallel_2\",45.0],'\n",
    "        'PARAMETER[\"latitude_of_center\",39.0],'\n",
    "        'UNIT[\"Meter\",1.0]]')\n",
    "\n",
    "    # Create the ee.Projection object\n",
    "    projection = ee.Projection(wkt)\n",
    "    \n",
    "    # Create a covering grid using the equal-distance projection. each cell is 1 patch\n",
    "    covering_grid = event.geometry().coveringGrid(projection, patchSize*scale).geometry().bounds(scale*0.9)\n",
    "    \n",
    "    # Return binary label, 1= burn pixels, 0 = unburnt pixels\n",
    "    extent = ee.Image.constant(1).clip(covering_grid)\n",
    "    burnt = ee.Image.constant(1).clip(event.geometry())\n",
    "        \n",
    "    label = extent.updateMask(burnt).unmask(0)\n",
    "    return label.rename('label')\n",
    "\n",
    "def downloadInstance(event, dateBuffer, patchSize, scale, id, rootdir):\n",
    "    # preOpt, s1pre, postOpt, s1post = getOpticalRadarPairs('LANDSAT_8', event, dateBuffer)\n",
    "    bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12', 'nbr', 'dnbr']\n",
    "    postOpt = getOpticalRadarPairs('Sentinel-2', True, event, dateBuffer).select(bands)\n",
    "    label = prepareLabel(event, patchSize, scale).where(postOpt.select('dnbr').lt(0.1), 0).toInt()\n",
    "    # eventInstance =  preOpt.addBands([s1pre.mosaic().regexpRename('$', '_pre'), postOpt, ee.Image(s1post.mosaic().regexpRename('$', '_post'))])\n",
    "    xfilename = Path(f\"{rootdir}/X/image_{id}.tif\")\n",
    "    if not os.path.exists(xfilename.parent):\n",
    "        os.makedirs(xfilename.parent)\n",
    "    BaseImage(postOpt).download(xfilename, crs='EPSG:4326', region= label.geometry(), scale= scale, overwrite=True, num_threads=20)\n",
    "    yfilename = Path(f\"C:/Users/coach/myfiles/postdoc/Fire/data/DNN/Y/label_{id}.tif\")\n",
    "    if not os.path.exists(yfilename.parent):\n",
    "        os.makedirs(yfilename.parent)\n",
    "    BaseImage(label).download(yfilename, crs='EPSG:4326', region= label.geometry(), scale= scale, overwrite=True, num_threads=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"C:/Users/coach/myfiles/postdoc/Fire/data/DNN\"\n",
    "\n",
    "for id in tqdm(range(34, mtbs_sz)):#mtbs_sz, 1616\n",
    "    fire = ee.Feature(mtbs_list.get(id))\n",
    "    try:\n",
    "        downloadInstance(fire, 15, 64, 30, id, rootdir)\n",
    "    except Exception as e:\n",
    "        print(f\"Fire event {id} failed with error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flipnslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flipnslide.tiling import FlipnSlide\n",
    "\n",
    "class FlipnSlideAug(torch.nn.Module):\n",
    "    def __init__(self, tilesize: int, viz: bool = False):\n",
    "        super().__init__()\n",
    "        self.tilesize = tilesize\n",
    "        self.viz = viz\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        if isinstance(inputs, dict):\n",
    "            # If input is a dictionary, process each item\n",
    "            return {key: self.process_tensor(value) for key, value in inputs.items()}\n",
    "        else:\n",
    "            # If input is a single tensor, process it directly\n",
    "            return self.process_tensor(inputs)\n",
    "    \n",
    "    def process_tensor(self, tensor):\n",
    "        # Ensure input is on CPU and convert to numpy\n",
    "        np_array = tensor.squeeze(0).cpu().numpy()\n",
    "        \n",
    "        sample_tiled = FlipnSlide(\n",
    "            tile_size=self.tilesize, \n",
    "            data_type='tensor',\n",
    "            save=False, \n",
    "            image=np_array,\n",
    "            viz=self.viz\n",
    "        )\n",
    "        \n",
    "        # Convert back to tensor and add batch dimension\n",
    "        return sample_tiled.tiles\n",
    "\n",
    "# Usage with AugmentationSequential\n",
    "flipnslide = FlipnSlideAug(tilesize=64, viz=False)\n",
    "tfms = AugmentationSequential(\n",
    "    flipnslide,\n",
    "    data_keys=None\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "train_batch = {\n",
    "    'image': torch.rand(1, 3, 256, 256),\n",
    "    'mask': torch.rand(1, 1, 256, 256)\n",
    "}\n",
    "\n",
    "transformed = tfms(train_batch)\n",
    "\n",
    "print(\"Transformed image shape:\", transformed['image'].shape)\n",
    "print(\"Transformed mask shape:\", transformed['mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flipnslide.tiling import FlipnSlide\n",
    "from kornia.augmentation.container import AugmentationSequential\n",
    "from kornia.constants import DataKey\n",
    "\n",
    "\n",
    "class FlipnSlideAug(torch.nn.Module):\n",
    "    def __init__(self, tilesize: int, viz: bool = False):\n",
    "        super().__init__()\n",
    "        self.tilesize = tilesize\n",
    "        self.viz = viz\n",
    "    \n",
    "    def forward(self, tensor):\n",
    "        # Process the input tensor directly\n",
    "        return self.process_tensor(tensor)\n",
    "    \n",
    "    def process_tensor(self, tensor):\n",
    "        # Ensure input is on CPU and convert to numpy\n",
    "        np_array = tensor.squeeze(0).cpu().numpy()\n",
    "        \n",
    "        sample_tiled = FlipnSlide(\n",
    "            tile_size=self.tilesize, \n",
    "            data_type='tensor',\n",
    "            save=False, \n",
    "            image=np_array,\n",
    "            viz=self.viz\n",
    "        )\n",
    "        \n",
    "        # Return the tiles directly\n",
    "        return sample_tiled.tiles\n",
    "\n",
    "# Usage with AugmentationSequential\n",
    "flipnslide = FlipnSlideAug(tilesize=64, viz=False)\n",
    "tfms = AugmentationSequential(\n",
    "    flipnslide,\n",
    "    data_keys=[DataKey.INPUT, DataKey.MASK]# Specify both keys\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "train_batch = {\n",
    "    'image': torch.rand(1, 3, 256, 256),\n",
    "    'mask': torch.rand(1, 1, 256, 256)\n",
    "}\n",
    "\n",
    "transformed = tfms(train_batch['image'], train_batch['mask'])\n",
    "\n",
    "print(\"Transformed image shape:\", transformed[0].shape)\n",
    "print(\"Transformed mask shape:\", transformed[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torchgeo.datasets import RasterDataset, stack_samples\n",
    "from torchgeo.samplers import RandomGeoSampler, Units\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchgeo.transforms import AugmentationSequential\n",
    "from kornia.augmentation.container import AugmentationSequential\n",
    "from flipnslide.tiling import FlipnSlide\n",
    "\n",
    "import torch \n",
    "class FlipnSlideAug(torch.nn.Module):\n",
    "    def __init__(self, tilesize: int, viz: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tilesize = tilesize\n",
    "        self.viz = viz\n",
    "\n",
    "    def forward(self, inputs: dict):\n",
    "\n",
    "        sample_tiled = FlipnSlide(tile_size=self.tilesize, data_type='tensor',\n",
    "                          save=False, image= inputs.squeeze(0).numpy(), viz = self.viz)\n",
    "\n",
    "        return sample_tiled.tiles\n",
    "\n",
    "root = Path(r\"C:\\Users\\coach\\myfiles\\postdoc\\Fire\\data\\DNN\")\n",
    "assert root.exists()\n",
    "\n",
    "train_imgs = RasterDataset(paths=(root/'X').as_posix(), crs='epsg:4326', res= 0.00025)\n",
    "train_msks = RasterDataset(paths=(root/'Y').as_posix(), crs='epsg:4326', res= 0.00025)\n",
    "\n",
    "# IMPORTANT\n",
    "train_msks.is_image = False\n",
    "\n",
    "flipnslide = FlipnSlideAug(tilesize=64, viz= False)\n",
    "tfms = AugmentationSequential(flipnslide,\n",
    "    data_keys = ['image', 'mask']\n",
    ")\n",
    "\n",
    "train_dset = train_imgs & train_msks\n",
    "\n",
    "train_sampler = RandomGeoSampler(train_imgs, size= 64*3, length=3, units=Units.PIXELS)\n",
    "\n",
    "train_dataloader = DataLoader(train_dset, sampler=train_sampler, batch_size=1, collate_fn=stack_samples)\n",
    "\n",
    "train_batch = next(iter(train_dataloader))\n",
    "del train_batch['crs']\n",
    "del train_batch['bbox']\n",
    "\n",
    "train_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_batch['mask'].shape)\n",
    "flipnslide(train_batch['mask']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_batch['image'].shape)\n",
    "print(train_batch['mask'].shape)\n",
    "\n",
    "print(tfms(train_batch['image'], train_batch['mask'])[1].shape)\n",
    "# print(tfms(train_batch)['mask'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once data is extracted, perform flipnslide\n",
    "from flipnslide.tiling import FlipnSlide\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timg = rio.open(r\"C:\\Users\\coach\\myfiles\\postdoc\\Fire\\data\\DNN\\X\\image_0.tif\")\n",
    "timg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sample_image = np.random.rand(114, 313, 763)\n",
    "sample_tiled = FlipnSlide(tile_size=64, data_type='tensor',\n",
    "                          save=False, image=sample_image, viz = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = sample_tiled.tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = startDate.get('year').getInfo()\n",
    "timelapse = geemap.landsat_timelapse(\n",
    "    event.geometry().bounds(),\n",
    "    out_gif='landsat.gif',\n",
    "    start_year= year,\n",
    "    end_year= year,\n",
    "    start_date='10-07',\n",
    "    end_date='12-30',\n",
    "    frequency='month',\n",
    "    bands=['SWIR2','NIR', 'Red'],#nir, swir2, gr\n",
    "    frames_per_second=1,\n",
    "    title='Landsat-8 Timelapse',\n",
    ")\n",
    "geemap.show_image(timelapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelapse = geemap.sentinel2_timelapse(\n",
    "    event.geometry().bounds(),\n",
    "    out_gif='sentinel2.gif',\n",
    "    start_year= year,\n",
    "    end_year= year,\n",
    "    start_date='05-01',\n",
    "    end_date='06-30',\n",
    "    frequency='week',\n",
    "    bands=['SWIR2','NIR', 'Red'],#nir, swir2, gr\n",
    "    frames_per_second=1,\n",
    "    title='Sentinel-2 Timelapse',\n",
    ")\n",
    "geemap.show_image(timelapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import ee\n",
    "import geemap\n",
    "from geeml.utils import eeprint\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = ee.FeatureCollection(\"projects/ee-geethensingh/assets/postdoc/FireRecords_GRNP\")\\\n",
    "    .filter(ee.Filter.stringContains('FIRE_ID', '99').Not()).filter(ee.Filter.gt('YEAR_', 2017)).map(\n",
    "    lambda ft: ft.set('Ig_Date', ee.Date.parse('YYYYMMdd',ft.get('DATE_BURNE')).format())\n",
    ")\n",
    "\n",
    "eeprint(fc.limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = fc.first()\n",
    "eventDate = ee.Date(event.get('Ig_Date'))\n",
    "print('event Date:', eventDate.format().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ee.Date.parse('YYYYMMdd', '20180712').format().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadInstance(event, dateBuffer, patchSize, scale, id, rootdir):\n",
    "    # preOpt, s1pre, postOpt, s1post = getOpticalRadarPairs('LANDSAT_8', event, dateBuffer)\n",
    "    bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12', 'nbr', 'dnbr']\n",
    "    postOpt = getOpticalRadarPairs('Sentinel-2', True, event, dateBuffer).select(bands)\n",
    "    label = prepareLabel(event, patchSize, scale).where(postOpt.select('dnbr').lt(0.1), 0).toInt()\n",
    "    # eventInstance =  preOpt.addBands([s1pre.mosaic().regexpRename('$', '_pre'), postOpt, ee.Image(s1post.mosaic().regexpRename('$', '_post'))])\n",
    "    xfilename = Path(f\"{rootdir}/X_test/image_{id}.tif\")\n",
    "    if not os.path.exists(xfilename.parent):\n",
    "        os.makedirs(xfilename.parent)\n",
    "    BaseImage(postOpt).download(xfilename, crs='EPSG:4326', region= label.geometry(), scale= scale, overwrite=True, num_threads=20)\n",
    "    # yfilename = Path(f\"C:/Users/coach/myfiles/postdoc/Fire/data/DNN/Y/label_{id}.tif\")\n",
    "    # if not os.path.exists(yfilename.parent):\n",
    "    #     os.makedirs(yfilename.parent)\n",
    "    # BaseImage(label).download(yfilename, crs='EPSG:4326', region= label.geometry(), scale= scale, overwrite=True, num_threads=20)\n",
    "\n",
    "fcSize = fc.size().getInfo()\n",
    "print(f\"There are {fcSize} fire events for GRNP\")\n",
    "fcList = fc.toList(fcSize)\n",
    "\n",
    "rootdir = \"C:/Users/coach/myfiles/postdoc/Fire/data/DNN\"\n",
    "\n",
    "for id in tqdm(range(0, 12)):\n",
    "    fire = ee.Feature(fcList.get(id))\n",
    "    try:\n",
    "        downloadInstance(fire, 15, 64, 30, id, rootdir)\n",
    "    except Exception as e:\n",
    "        print(f\"Fire event {id} failed with error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking burn areas to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee \n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "\n",
    "from geeml.utils import eeprint\n",
    "import geemap\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format ecosystem function types so that they can automatically be uploaded to GEE\n",
    "\n",
    "import os\n",
    "\n",
    "# Path to the folder containing .tif files\n",
    "folder_path = r\"C:\\Users\\coach\\myfiles\\data\\all-maps-raster-geotiff\\terrestrial\"\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.tif'):\n",
    "        # Replace all full stops except the last one before the extension\n",
    "        new_filename = filename.replace('.', '_').replace('.tif', '_tif')\n",
    "        \n",
    "        # Rename the file\n",
    "        os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_filename))\n",
    "\n",
    "print(\"Renaming complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = ee.Image(\"CSP/ERGo/1_0/Global/SRTM_topoDiversity\").rename(\"topDiversity\")\n",
    "glo30 = ee.ImageCollection(\"projects/sat-io/open-datasets/GLO-30\")\n",
    "aspect = glo30.map(lambda img: ee.Terrain.aspect(img).rename('aspect')).mosaic()\n",
    "# chili = ee.Image(\"CSP/ERGo/1_0/Global/SRTM_CHILI\")\n",
    "# biome = ee.FeatureCollection(\"RESOLVE/ECOREGIONS/2017\").reduceToImage(['BIOME_NUM'], ee.Reducer.first()).rename(\"biome\")\n",
    "cropland = ee.ImageCollection(\"users/potapovpeter/Global_cropland_2019\").mosaic().rename(\"cropland\")\n",
    "water = ee.Image(ee.ImageCollection(\"JRC/GSW1_4/YearlyHistory\").filterDate(\"2021-01-01\", \"2022-01-01\").first()).gte(2).unmask(0).rename('water')\n",
    "treeCov =  ee.Image(ee.ImageCollection(\"projects/sat-io/open-datasets/GFCC30TC\").filter(ee.Filter.eq('system:index', 'GFCC30TC_2015_V4')).first()).rename('treeCov')\n",
    "EFT = ee.ImageCollection(\"projects/ee-gsingh/assets/terrestrial/realm_T\").map(lambda img: img.gte(1).unmask(0).rename([img.get('id_no')])).toBands()\n",
    "\n",
    "meanBands = cropland.addBands([water, td, aspect, treeCov, EFT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeprint(meanBands.bandNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burn areas from MODIS \n",
    "fc = ee.FeatureCollection(\"projects/ee-geethensingh/assets/postdoc/FireRecords_GRNP\")\\\n",
    "    .filter(ee.Filter.stringContains('FIRE_ID', '99').Not()).filter(ee.Filter.gt('YEAR_', 2017)).map(\n",
    "    lambda ft: ft.set('Ig_Date', ee.Date.parse('YYYYMMdd',ft.get('DATE_BURNE')).format())\n",
    ")\n",
    "\n",
    "eeprint(fc.limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = ee.FeatureCollection(\"projects/ee-geethensingh/assets/postdoc/proj_fired_south_africa_to2021182_events\").map(\n",
    "    lambda ft: ft.set('Ig_Date', ee.Date(ft.get('ig_date')).format())\n",
    ").filter(ee.Filter.gte('ig_year', 2017))\n",
    "eeprint(fc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to create batches for large featureCollection\n",
    "def kfolds_random(table, k, percent=None, replacement=False, seed=0xbeef):\n",
    "    if percent is None:\n",
    "        percent = 1.0 / k\n",
    "    \n",
    "    folds = ee.List.sequence(0, k - 1).map(lambda n: get_fold(n, table, k, percent, replacement, seed))\n",
    "    return folds\n",
    "\n",
    "def get_fold(n, table, k, percent, replacement, seed):\n",
    "    n = ee.Number(n)\n",
    "    offset = ee.Algorithms.If(replacement, n, 0)\n",
    "    repl_seed = ee.Number(seed).add(offset)\n",
    "    \n",
    "    t = table.randomColumn('random', repl_seed)\n",
    "    slice_filter = ee.Filter.And(\n",
    "        ee.Filter.gte('random', ee.Number(percent).multiply(n)),\n",
    "        ee.Filter.lt('random', ee.Number(percent).multiply(n.add(1)))\n",
    "    )\n",
    "    return t.filter(slice_filter)\n",
    "\n",
    "# Example usage:\n",
    "# k = 92\n",
    "# folds = kfolds_random(pas, k)\n",
    "# eeprint(ee.FeatureCollection(folds.get(0)).limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k =200\n",
    "folds = kfolds_random(fc, k)\n",
    "eeprint(ee.FeatureCollection(folds.get(0)).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetadata(feature, meanLayers, properties):\n",
    "    meanResult = meanLayers.reduceRegion(reducer = ee.Reducer.mean(), geometry = feature.geometry(), scale = 30, maxPixels =1e9)\n",
    "    return feature.set(meanResult).select(properties)\n",
    "\n",
    "test = fc.map(lambda ft: getMetadata(ft.bounds(), meanLayers= meanBands, properties = meanBands.bandNames().cat(['ig_date', 'last_date'])))\n",
    "eeprint(test.limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRNPFireRecords = ee.data.computeFeatures({\n",
    "    'expression': test,\n",
    "    'fileFormat': 'GEOPANDAS_GEODATAFRAME'\n",
    "})\n",
    "\n",
    "# Need to set the CRS.\n",
    "# Make sure it matches the CRS of FeatureCollection geometries.\n",
    "GRNPFireRecords.crs = 'EPSG:4326'\n",
    "\n",
    "display(type(GRNPFireRecords))\n",
    "GRNPFireRecords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200\n",
    "folds = kfolds_random(fc, k)\n",
    "csv_file_path = r\"C:\\Users\\coach\\myfiles\\data\\fired_metadata.csv\"\n",
    "\n",
    "for i in tqdm(range(0, k)):\n",
    "    fts = ee.FeatureCollection(folds.get(i))\n",
    "    data = fts.map(lambda ft: getMetadata(ft.bounds(), meanLayers=meanBands, properties=meanBands.bandNames().cat(['ig_date', 'last_date'])))\n",
    "\n",
    "    # Conversion to GeoDataFrame\n",
    "    gdf = ee.data.computeFeatures({\n",
    "        'expression': data,\n",
    "        'fileFormat': 'GEOPANDAS_GEODATAFRAME'\n",
    "    })\n",
    "    gdf.crs = 'EPSG:4326'\n",
    "\n",
    "    # Convert the geometry column to WKT\n",
    "    gdf['geometry'] = gdf['geometry'].apply(lambda geom: geom.wkt)\n",
    "\n",
    "    # Determine if it's the first iteration (i == 0)\n",
    "    write_header = i == 0\n",
    "\n",
    "    # Write the GeoDataFrame to CSV\n",
    "    gdf.to_csv(csv_file_path, mode='a', header=write_header, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = r\"C:\\Users\\coach\\myfiles\\data\\fired_metadata.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# clip tree cover values greater than 100 to 100\n",
    "df['treeCov'] = df['treeCov'].clip(upper=100)\n",
    "\n",
    "# Check for columns with only zeros and drop them\n",
    "zero_columns = df.columns[df.eq(0).all()]\n",
    "df = df.drop(zero_columns, axis=1)\n",
    "\n",
    "# Perform exploratory data analysis\n",
    "eda_columns = ['aspect', 'cropland', 'topDiversity', 'treeCov', 'water']\n",
    "eda_columns = [col for col in eda_columns if col in df.columns]\n",
    "\n",
    "if eda_columns:\n",
    "    print(df[eda_columns].describe())\n",
    "    print(df[eda_columns].corr())\n",
    "else:\n",
    "    print(\"All specified columns have been dropped due to containing only zeros.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create histograms for each column\n",
    "eda_columns = ['aspect', 'cropland', 'topDiversity', 'treeCov', 'water']\n",
    "eda_columns = [col for col in eda_columns if col in df.columns]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(eda_columns), figsize=(10, 20))\n",
    "for ax, col in zip(axes, eda_columns):\n",
    "    sns.histplot(df[col], ax=ax)\n",
    "    ax.set_title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create box plots for each column\n",
    "fig, axes = plt.subplots(nrows=len(eda_columns), figsize=(10, 20))\n",
    "for ax, col in zip(axes, eda_columns):\n",
    "    sns.boxplot(df[col], ax=ax)\n",
    "    ax.set_title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create scatter plots to visualize relationships between columns\n",
    "fig, axes = plt.subplots(nrows=len(eda_columns), ncols=len(eda_columns), figsize=(20, 20))\n",
    "for i, col1 in enumerate(eda_columns):\n",
    "    for j, col2 in enumerate(eda_columns):\n",
    "        if i == j:\n",
    "            sns.histplot(df[col1], ax=axes[i, j])\n",
    "        elif i > j:\n",
    "            axes[i, j].axis('off')\n",
    "        else:\n",
    "            sns.scatterplot(x=col1, y=col2, data=df, ax=axes[i, j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking instances to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file_path = r\"C:\\Users\\coach\\myfiles\\data\\fired_metadata.csv\"\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aspect\n",
    "\n",
    "# Define a function to map aspect to cardinal points\n",
    "def map_aspect_to_cardinal(aspect):\n",
    "    if 337.5 <= aspect <= 360 or 0 <= aspect <= 22.5:\n",
    "        return 'N'\n",
    "    elif 22.5 < aspect <= 67.5:\n",
    "        return 'NE'\n",
    "    elif 67.5 < aspect <= 112.5:\n",
    "        return 'E'\n",
    "    elif 112.5 < aspect <= 157.5:\n",
    "        return 'SE'\n",
    "    elif 157.5 < aspect <= 202.5:\n",
    "        return 'S'\n",
    "    elif 202.5 < aspect <= 247.5:\n",
    "        return 'SW'\n",
    "    elif 247.5 < aspect <= 292.5:\n",
    "        return 'W'\n",
    "    elif 292.5 < aspect <= 337.5:\n",
    "        return 'NW'\n",
    "\n",
    "# Apply the function to the 'aspect' column\n",
    "df['cardinal'] = df['aspect'].apply(map_aspect_to_cardinal)\n",
    "\n",
    "# Create a dictionary to map cardinal directions to unique integers\n",
    "cardinal_map = {'N': 1, 'NE': 2, 'E': 3, 'SE': 4, 'S': 5, 'SW': 6, 'W': 7, 'NW': 8}\n",
    "\n",
    "# Map cardinal directions to unique integers\n",
    "df['cardinal_id'] = df['cardinal'].map(cardinal_map)\n",
    "\n",
    "# Normalize topDiversity and treeCov\n",
    "df[['topDiversity', 'treeCov']] = df[['topDiversity', 'treeCov']].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "# Compute the row-wise mean for the specified variables\n",
    "eda_columns = ['cropland', 'topDiversity', 'treeCov', 'water']\n",
    "\n",
    "df['priority_score'] = df[eda_columns].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all columns that start with 'T'\n",
    "t_columns = [col for col in df.columns if col.startswith('T')]\n",
    "df['counts'] = df[t_columns].ne(0).sum(axis=1)\n",
    "\n",
    "# Create a new column 'dominant' based on the index of column in t_columns that has the highest value\n",
    "df['dominant'] = df[t_columns].idxmax(axis=1)\n",
    "df['dominant_idx'] = np.argmax(df[t_columns].values, axis=1)\n",
    "\n",
    "# Create a new column 'unique_id' based on unique combinations of 'counts' and 'dominant_idx'\n",
    "df['unique_id'] = df.groupby(['counts', 'dominant_idx', 'cardinal_id']).ngroup()\n",
    "# Double check the unique id\n",
    "print('Each combination has a unique code:', df.groupby(['counts', 'dominant_idx', 'cardinal_id'])['unique_id'].nunique().max() == 1)\n",
    "print('Total number of unque combinations:', df['unique_id'].nunique())\n",
    "\n",
    "# assuming df is a pandas DataFrame\n",
    "df['counts'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Value Counts of Counts Column')\n",
    "plt.xlabel('Number of mixed ecosystems')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "df['dominant'].value_counts().plot(kind='bar')\n",
    "plt.title('Value Counts of Counts Column')\n",
    "plt.xlabel('Dominant ecosystem index')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "df['unique_id'].value_counts().plot(kind='bar')\n",
    "plt.title('Value Counts of unique ID Column')\n",
    "plt.xlabel('unique combinations of count and dominant columns')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics\n",
    "summary_stats = df['unique_id'].value_counts().describe()\n",
    "\n",
    "# Print summary statistics\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the indices for each unique id\n",
    "unique_id_indices = {}\n",
    "\n",
    "top_k = 5\n",
    "\n",
    "# Iterate over each unique id\n",
    "for unique_id in df['unique_id'].unique():\n",
    "    # Get the rows for the current unique id\n",
    "    unique_id_df = df[df['unique_id'] == unique_id]\n",
    "    \n",
    "    # If there are 5 or fewer rows, include all indices\n",
    "    if len(unique_id_df) <= top_k:\n",
    "        unique_id_indices[unique_id] = unique_id_df.index.tolist()\n",
    "    # If there are more than 5 rows, select the 5 rows with the highest priority_score\n",
    "    else:\n",
    "        unique_id_indices[unique_id] = unique_id_df.nlargest(top_k, 'priority_score').index.tolist()\n",
    "\n",
    "# Create a list of indices\n",
    "indices = [index for indices in unique_id_indices.values() for index in indices]\n",
    "\n",
    "# Print the list of indices\n",
    "print(len(indices))\n",
    "\n",
    "print(unique_id_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first unique id\n",
    "first_unique_id = df['unique_id'].unique()[0]\n",
    "print(first_unique_id)\n",
    "\n",
    "# Get the indices for the first unique id\n",
    "first_unique_id_indices = unique_id_indices[first_unique_id]\n",
    "print(first_unique_id_indices)\n",
    "\n",
    "# Verify the indices by checking the corresponding rows in the DataFrame\n",
    "display(df.loc[first_unique_id_indices])\n",
    "\n",
    "# Check if the length of the indices is correct\n",
    "print(len(first_unique_id_indices))\n",
    "\n",
    "# Check if the indices correspond to the correct unique id\n",
    "print(df.loc[first_unique_id_indices, 'unique_id'].unique())\n",
    "\n",
    "# Check if the indices correspond to the top 5 priority scores (if applicable)\n",
    "if len(df[df['unique_id'] == first_unique_id]) > 3:\n",
    "    print(df.loc[first_unique_id_indices, 'priority_score'].tolist())\n",
    "    print(df.loc[first_unique_id_indices, 'priority_score'].tolist() == df[df['unique_id'] == first_unique_id].nlargest(3, 'priority_score')['priority_score'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFires = df.loc[indices]\n",
    "\n",
    "# Step 2: Convert the WKT strings back to Shapely geometry objects\n",
    "labelFires['geometry'] = gpd.GeoSeries.from_wkt(labelFires['geometry'])\n",
    "\n",
    "# Step 3: Create a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(labelFires, geometry='geometry')\n",
    "gdf.crs = 'EPSG:4326'\n",
    "\n",
    "# Save as shapefile\n",
    "gdf.to_file(r\"C:\\Users\\coach\\myfiles\\data\\firesToLabelv2.shp\")\n",
    "# Upload shp to GEE\n",
    "# gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download site data for labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import ee\n",
    "import geemap\n",
    "from geeml.utils import eeprint\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"a6354f4e-b290-4403-b1f2-2f22bc6047b4\" style=\"height: auto; width:100%;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " \n",
       "        <script src=\"/static/components/requirejs/require.js\"></script> <!-- Needed in Colab -->\n",
       "        <script>\n",
       "            require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
       "              renderjson.set_show_to_level(1)\n",
       "              document.getElementById('a6354f4e-b290-4403-b1f2-2f22bc6047b4').appendChild(renderjson(1552))\n",
       "            });\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fc = ee.FeatureCollection(\"projects/ee-geethensingh/assets/postdoc/firesToLabelv2\").map(\n",
    "    lambda ft: ft.set('Ig_Date', ee.Date(ft.get('ig_date')).format())\n",
    ")\n",
    "\n",
    "fcList = fc.toList(1552)\n",
    "eeprint(fc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event Date: 2020-09-07T00:00:00\n"
     ]
    }
   ],
   "source": [
    "event = fc.first()\n",
    "eventDate = ee.Date(event.get('Ig_Date'))\n",
    "print('event Date:', eventDate.format().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocessOptical(image, sensor):\n",
    "    \"\"\"Select Bands and scale between 0 and 1\n",
    "    \"\"\"\n",
    "    bandSelect = {'Sentinel-2': 'B.*',\n",
    "                    'LANDSAT_8': 'SR_B.',\n",
    "                    'LANDSAT_9': 'SR_B.'}\n",
    "    # Step 2) radiometric correction\n",
    "    radiometricMultiplySelect = {'Sentinel-2': 0.0001,\n",
    "                    'LANDSAT_8': 0.0000275,\n",
    "                    'LANDSAT_9': 0.0000275}\n",
    "    radiometricAddSelect = {'Sentinel-2': 0,\n",
    "                    'LANDSAT_8': -0.2,\n",
    "                    'LANDSAT_9': -0.2}\n",
    "    \n",
    "    # Step 3) depending on image selected, select cloud band\n",
    "    return image.select(bandSelect.get(sensor)).multiply(radiometricMultiplySelect.get(sensor)).add(radiometricAddSelect.get(sensor)).copyProperties(image)\n",
    "\n",
    "# Sentinel-2 data exploration\n",
    "def cloudMask1(imageCollection):\n",
    "    #  Cloud Score+ image collection. Note Cloud Score+ is produced from Sentinel-2\n",
    "        # Level 1C data and can be applied to either L1C or L2A collections.\n",
    "        csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED')\n",
    "\n",
    "        #  Use 'cs' or 'cs_cdf', depending on your use-case; see docs for guidance.\n",
    "        QA_BAND = 'cs'\n",
    "\n",
    "        # The threshold for masking; values between 0.50 and 0.65 generally work well.\n",
    "        # Higher values will remove thin clouds, haze & cirrus shadows.\n",
    "        CLEAR_THRESHOLD = 0.6\n",
    "\n",
    "        # link Sentinel-2 image with corresponding Cloud Score+\n",
    "        cloudMask = imageCollection.linkCollection(csPlus, [QA_BAND]).map(lambda img:\n",
    "            img.updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD)).select('B.*').divide(10000))\n",
    "\n",
    "        # scale and mask out clouds\n",
    "        return cloudMask\n",
    "\n",
    "def cloudMask2(imageCollection):\n",
    "        #  Cloud Score+ image collection. Note Cloud Score+ is produced from Sentinel-2\n",
    "        # Level 1C data and can be applied to either L1C or L2A collections.\n",
    "        csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED')\n",
    "\n",
    "        #  Use 'cs' or 'cs_cdf', depending on your use-case; see docs for guidance.\n",
    "        QA_BAND = 'cs'\n",
    "\n",
    "        # The threshold for masking; values between 0.50 and 0.65 generally work well.\n",
    "        # Higher values will remove thin clouds, haze & cirrus shadows.\n",
    "        CLEAR_THRESHOLD = 0.6\n",
    "        \n",
    "        # radiometric correction and band selection\n",
    "        # preProcessCollection = imageCollection.map(lambda image: preprocessOptical(image, 'Sentinel-2'))\n",
    "        # link Sentinel-2 image with corresponding Cloud Score+\n",
    "        # cloudMask = imageCollection.linkCollection(csPlus, [QA_BAND]).map(lambda img:\n",
    "        #     img.addBands(img.normalizedDifference(['B8', 'B12']).multiply(10000).rename('nbr'))\\\n",
    "        #         .updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD)).select(['B.*', 'nbr']).divide(10000)\n",
    "        #     )\n",
    "        cloudMask = imageCollection.linkCollection(csPlus, [QA_BAND]).map(lambda img:\n",
    "            img.select(['B.*'])\\\n",
    "                .updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD)).divide(10000)\\\n",
    "                    .addBands(img.normalizedDifference(['B8A', 'B12']).rename('nbr'))\n",
    "            )\n",
    "            \n",
    "        # scale and mask out clouds\n",
    "        return cloudMask\n",
    "\n",
    "def qualityMosaicPercentile(collection, QAband, percentile):\n",
    "    # Compute percentile image\n",
    "    percentileImage = collection.select(QAband).reduce(ee.Reducer.percentile([percentile]))\n",
    "    #  Compute distance of every pixel from the computed percentile in that location\n",
    "    withDist = ee.ImageCollection(collection.map(lambda image: image.addBands([\n",
    "        image.select(QAband).subtract(percentileImage).abs().multiply(-1).rename('quality')])))\n",
    "    return withDist.qualityMosaic('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(sensor: str, pre: bool, event: ee.Feature, dateBuffer: int)->ee.Image:\n",
    "    \"\"\"\n",
    "    Get the temporally closest pre-fire and post-fire optical or radar images after preprocessing both\n",
    "     the optical images.\n",
    "\n",
    "    Args:\n",
    "        event (ee.Feature): A fire event delineating the boundary of burnt area\n",
    "        dateBuffer (int): The temporal window to locate a relevant image. In units of weeks.\n",
    "\n",
    "    Returns:\n",
    "        A pre-fire and post-fire optical or radar image\n",
    "    \"\"\"\n",
    "    # Filter images that intersect the geometry using the optimised filterBounds. Thereafter, use the\n",
    "    # ee.filter.contains that is not as optimised as filterBounds\n",
    "    images = supportedSensors.get(sensor).filterBounds(event.geometry())\n",
    "    eventDate = ee.Date(event.get('Ig_Date'))\n",
    "    if pre:\n",
    "        startDate = eventDate.advance(dateBuffer*-1, 'week')\n",
    "        endDate = eventDate\n",
    "        outImage = cloudMask1(images.filterDate(startDate, endDate).sort('system:time_start', False)).reduce(ee.Reducer.firstNonNull()).regexpRename('.{6}$','')\n",
    "        # .filter(ee.Filter.contains('.geo', event.geometry())).sort('system:time_start', False).first()\n",
    "  \n",
    "    else:\n",
    "        # postfire\n",
    "        startDate = eventDate\n",
    "        endDate = eventDate.advance(dateBuffer, 'week')\n",
    "        outImage = cloudMask2(images.filterDate(startDate, endDate))#.reduce(ee.Reducer.firstNonNull()).regexpRename('.{6}$','')#.qualityMosaic('nbr')\n",
    "        # .filter(ee.Filter.contains('.geo', event.geometry())).sort('system:time_start', True).first()\n",
    "    \n",
    "    return outImage\n",
    "\n",
    "    # Given a fire event get pre and post fire image from multi-sensors\n",
    "def getOpticalRadarPairs(sensor:str, dnbr:bool, event: ee.Feature, dateBuffer: int = 4)-> ee.Image:\n",
    "    \"\"\"\n",
    "     Get optical-radar pairs for a given fire event. First image after fire event and image before fire event\n",
    "\n",
    "     Args:\n",
    "        sensor(str): The name of the sensor. One of ['Sentinel-1', 'Sentinel-2', 'Landsat_8', 'Landsat_9']\n",
    "        event(ee.Feature): A fire event\n",
    "        dateBuffer(int): The temporal-search window. \n",
    "    \n",
    "    Returns:\n",
    "        An image with optical-radar pairs\n",
    "\n",
    "    \"\"\"\n",
    "    # Post-fire image\n",
    "    if sensor != 'any':\n",
    "        postOpticalImage = getImage(sensor, False, event, dateBuffer= dateBuffer)\n",
    "    else:\n",
    "        s2post = getImage('Sentinel-2', False, event, dateBuffer= dateBuffer)\n",
    "        l8post = getImage('LANDSAT_8', False, event, dateBuffer= dateBuffer)\n",
    "        l9post = getImage('LANDSAT_9', False, event, dateBuffer= dateBuffer)\n",
    "        # get the earliest optical image (between L8, L9 and S2) that was captured after the fire event\n",
    "        postOpticalImage = ee.ImageCollection.fromImages([s2post, l8post, l9post]).sort('system:time_start', True).first()\n",
    "    # pre-process post-fire image\n",
    "    # postOpticalImage = ee.Image(preprocessOptical(postOpticalImage, sensor).copyProperties(postOpticalImage))\n",
    "\n",
    "    # if sensor == 'Sentinel-1':\n",
    "    #     # RADAR\n",
    "    #     s1post = getImage('Sentinel-1', False, event, dateBuffer= dateBuffer)\n",
    "    #     # preprocess pre-fire radar image\n",
    "    #     parameters.update({'STOP_DATE': s1post.date().advance(1, 'day'), 'START_DATE': s1post.date(), 'ROI': event.geometry()})\n",
    "    #     s1post = wp.s1_preproc(parameters).select('V.')\n",
    "    \n",
    "    # pre-fire\n",
    "    if sensor != 'any':\n",
    "        # If only one sensor is to be used\n",
    "        preOpticalImage = getImage(sensor, True, event, dateBuffer= dateBuffer)\n",
    "    else:\n",
    "        # If any optical sensor is to be used\n",
    "        s2pre = getImage('Sentinel-2', True, event, dateBuffer= dateBuffer)\n",
    "        l8pre = getImage('LANDSAT_8', True, event, dateBuffer= dateBuffer)\n",
    "        l9pre = getImage('LANDSAT_9', True, event, dateBuffer= dateBuffer)\n",
    "        # get the earliest optical image (between L8, L9 and S2) that was captured after the fire event\n",
    "        preOpticalImage = ee.ImageCollection.fromImages([s2pre, l8pre, l9pre]).sort('system:time_start', True).first()\n",
    "    \n",
    "    # elif multisensor:\n",
    "    #     # if multisensor data is to be used, add radar to optical\n",
    "    #     # RADAR\n",
    "    #     s1pre = getImage('Sentinel-1', True, event, dateBuffer= dateBuffer)\n",
    "    #     # preprocess pre-fire radar image\n",
    "    #     parameters.update({'STOP_DATE': s1pre.date().advance(1, 'day'), 'START_DATE': s1pre.date(), 'ROI': event.geometry()})\n",
    "    #     s1pre = wp.s1_preproc(parameters).select('V.')\n",
    "\n",
    "    # pre-process pre-fire image\n",
    "    # preOpticalImage = ee.Image(preprocessOptical(preOpticalImage, sensor).copyProperties(preOpticalImage))\n",
    "\n",
    "    if dnbr:\n",
    "        postOpticalImage = qualityMosaicPercentile(postOpticalImage.map(lambda img: img.addBands(\n",
    "            preOpticalImage.normalizedDifference(['B8A', 'B12']).subtract(img.normalizedDifference(['B8A', 'B12'])).rename('dnbr'))), 'dnbr', 95) \n",
    "    \n",
    "    return postOpticalImage\n",
    "    # return preOpticalImage.regexpRename('$', '_pre'), s1pre, postOpticalImage.regexpRename('$', '_post'), s1post\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareLabel(event: ee.Feature, patchSize: int, scale: int)-> ee.Image:\n",
    "    \"\"\"\n",
    "    Converts a burn area polygon (ee.Feature) to a raster label. Burnt pixels are assigned a value of 1.\n",
    "    Unburnt pixels are assigned a value of 0. the returned ee.Image dimensions should closely approximate\n",
    "    the number of pixels divisible by the patchSize.\n",
    "\n",
    "    Args:\n",
    "        event(ee.Feature): The delineated burn area polygon to rasterize.\n",
    "        patchSize (int): The desirable patch dimension when training the DNN model.\n",
    "        scale (int): The desired output scale for the label.\n",
    "\n",
    "    Returns:\n",
    "        The rasterised label (ee.Image)\n",
    "    \"\"\"\n",
    "    # Define the WKT string for EPSG:102005\n",
    "    wkt = ('PROJCS[\"USA_Contiguous_Equidistant_Conic\",'\n",
    "        'GEOGCS[\"GCS_North_American_1983\",'\n",
    "        'DATUM[\"D_North_American_1983\",'\n",
    "        'SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],'\n",
    "        'PRIMEM[\"Greenwich\",0.0],'\n",
    "        'UNIT[\"Degree\",0.0174532925199433]],'\n",
    "        'PROJECTION[\"Equidistant_Conic\"],'\n",
    "        'PARAMETER[\"False_Easting\",0.0],'\n",
    "        'PARAMETER[\"False_Northing\",0.0],'\n",
    "        'PARAMETER[\"longitude_of_center\",-96.0],'\n",
    "        'PARAMETER[\"Standard_Parallel_1\",33.0],'\n",
    "        'PARAMETER[\"Standard_Parallel_2\",45.0],'\n",
    "        'PARAMETER[\"latitude_of_center\",39.0],'\n",
    "        'UNIT[\"Meter\",1.0]]')\n",
    "\n",
    "    # Create the ee.Projection object\n",
    "    projection = ee.Projection(wkt)\n",
    "    \n",
    "    # Create a covering grid using the equal-distance projection. each cell is 1 patch\n",
    "    covering_grid = event.geometry().coveringGrid(projection, patchSize*scale).geometry().bounds(scale*0.9)\n",
    "    \n",
    "    # Return binary label, 1= burn pixels, 0 = unburnt pixels\n",
    "    extent = ee.Image.constant(1).clip(covering_grid)\n",
    "    burnt = ee.Image.constant(1).clip(event.geometry())\n",
    "        \n",
    "    label = extent.updateMask(burnt).unmask(0)\n",
    "    return label.rename('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadInstance(event, dateBuffer, patchSize, scale, id, rootdir):\n",
    "    bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12', 'nbr', 'dnbr']\n",
    "    postOpt = getOpticalRadarPairs('Sentinel-2', True, event, dateBuffer).select(bands)\n",
    "    label = prepareLabel(event, patchSize, scale).where(postOpt.select('dnbr').lt(0.1), 0).toInt()\n",
    "    xfilename = Path(f\"{rootdir}/X/image_{id}.tif\")\n",
    "    if not os.path.exists(xfilename.parent):\n",
    "        os.makedirs(xfilename.parent)\n",
    "    BaseImage(postOpt).download(xfilename, crs='EPSG:4326', region= label.geometry(), scale= scale, overwrite=True, num_threads=20)\n",
    "    yfilename = Path(f\"{rootdir}/Y/label_{id}.tif\")\n",
    "    if not os.path.exists(yfilename.parent):\n",
    "        os.makedirs(yfilename.parent)\n",
    "    BaseImage(label).download(yfilename, crs='EPSG:4326', region= label.geometry(), scale= scale, overwrite=True, num_threads=20)\n",
    "\n",
    "fcSize = fc.size().getInfo()\n",
    "print(f\"There are {fcSize} fire events for labelling\")\n",
    "fcList = fc.toList(fcSize)\n",
    "\n",
    "rootdir = \"C:/Users/coach/myfiles/postdoc/Fire/data/toLabel\"\n",
    "\n",
    "for id in tqdm(range(fcSize)):\n",
    "    fire = ee.Feature(fcList.get(id))\n",
    "    try:\n",
    "        downloadInstance(fire, 15, 256, 30, id, rootdir)\n",
    "    except Exception as e:\n",
    "        print(f\"Fire event {id} failed with error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87eba44139f482fa6112f2f30e25e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa749f5facb405c8007b324067d0a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def create_chips(input_folder, output_folder, chip_size=256):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for filename in tqdm(os.listdir(input_folder)):\n",
    "        if filename.endswith('.tif'):\n",
    "            filepath = os.path.join(input_folder, filename)\n",
    "            \n",
    "            with rasterio.open(filepath) as src:\n",
    "                width, height = src.width, src.height\n",
    "                meta = src.meta.copy()\n",
    "                \n",
    "                for i in range(0, width, chip_size):\n",
    "                    for j in range(0, height, chip_size):\n",
    "                        # Ensure that only 256x256 chips are saved\n",
    "                        if (i + chip_size <= width) and (j + chip_size <= height):\n",
    "                            window = Window(i, j, chip_size, chip_size)\n",
    "                            transform = src.window_transform(window)\n",
    "                            \n",
    "                            chip = src.read(window=window)\n",
    "                            chip_meta = meta.copy()\n",
    "                            chip_meta.update({\n",
    "                                \"height\": chip.shape[1],\n",
    "                                \"width\": chip.shape[2],\n",
    "                                \"transform\": transform\n",
    "                            })\n",
    "                            \n",
    "                            chip_filename = f\"{os.path.splitext(filename)[0]}_{i}_{j}.tif\"\n",
    "                            chip_filepath = os.path.join(output_folder, chip_filename)\n",
    "                            \n",
    "                            with rasterio.open(chip_filepath, 'w', **chip_meta) as dst:\n",
    "                                dst.write(chip)\n",
    "\n",
    "# Usage\n",
    "input_folder = r'C:\\Users\\coach\\myfiles\\postdoc\\Fire\\data\\toLabel\\X'\n",
    "output_folder = r'C:\\Users\\coach\\myfiles\\postdoc\\Fire\\data\\toLabel\\X_chips'\n",
    "\n",
    "create_chips(input_folder, output_folder, chip_size=256)\n",
    "\n",
    "input_folder = r'C:\\Users\\coach\\myfiles\\postdoc\\Fire\\data\\toLabel\\Y'\n",
    "output_folder = r'C:\\Users\\coach\\myfiles\\postdoc\\Fire\\data\\toLabel\\Y_chips'\n",
    "\n",
    "create_chips(input_folder, output_folder, chip_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "\n",
    "def check_chip_sizes(output_folder, expected_size=(256, 256)):\n",
    "    for filename in tqdm(os.listdir(output_folder)):\n",
    "        if filename.endswith('.tif'):\n",
    "            filepath = os.path.join(output_folder, filename)\n",
    "            \n",
    "            with rasterio.open(filepath) as src:\n",
    "                width, height = src.width, src.height\n",
    "                \n",
    "                if (width, height) != expected_size:\n",
    "                    print(f\"{filename} is {width}x{height} pixels\")\n",
    "\n",
    "output_folder = r'C:\\Users\\coach\\myfiles\\postdoc\\Fire\\data\\toLabel\\X_chips'\n",
    "check_chip_sizes(output_folder)\n",
    "output_folder = r'C:\\Users\\coach\\myfiles\\postdoc\\Fire\\data\\toLabel\\Y_chips'\n",
    "check_chip_sizes(output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise gif for fire event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"a51cd280-8a1e-4f8c-aee9-9817f47198ca\" style=\"height: auto; width:100%;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " \n",
       "        <script src=\"/static/components/requirejs/require.js\"></script> <!-- Needed in Colab -->\n",
       "        <script>\n",
       "            require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
       "              renderjson.set_show_to_level(1)\n",
       "              document.getElementById('a51cd280-8a1e-4f8c-aee9-9817f47198ca').appendChild(renderjson(1552))\n",
       "            });\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geemap\n",
    "import ee\n",
    "ee.Initialize()\n",
    "from geeml.utils import eeprint\n",
    "\n",
    "fc = ee.FeatureCollection(\"projects/ee-geethensingh/assets/postdoc/firesToLabelv2\").map(\n",
    "    lambda ft: ft.set('Ig_Date', ee.Date(ft.get('ig_date')).format())\n",
    ")\n",
    "\n",
    "fcList = fc.toList(1552)\n",
    "eeprint(fc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-10\n",
      "Year: 2019\n",
      "Start Date: 06-27\n",
      "End Date: 10-25\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_dates(date_str):\n",
    "    date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    year = date.year\n",
    "    \n",
    "    start_date = date - timedelta(days=75)\n",
    "    end_date = date + timedelta(days=45)\n",
    "    \n",
    "    start_date_str = start_date.strftime('%m-%d')\n",
    "    end_date_str = end_date.strftime('%m-%d')\n",
    "    \n",
    "    return year, str(start_date_str), str(end_date_str)\n",
    "\n",
    "idx = 1538\n",
    "event = ee.Feature(fcList.get(idx))\n",
    "date_str = event.get('ig_date').getInfo()\n",
    "print(date_str)\n",
    "year, start_date, end_date = get_dates(date_str)\n",
    "\n",
    "print(f\"Year: {year}\")\n",
    "print(f\"Start Date: {start_date}\")\n",
    "print(f\"End Date: {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL...\n",
      "Downloading GIF image from https://earthengine.googleapis.com/v1/projects/earthengine-legacy/videoThumbnails/375996630b83e5d536f685557f69ca0f-6411eab69664f4e5be279451333165e5:getPixels\n",
      "Please wait ...\n",
      "The GIF image has been saved to: c:\\Users\\coach\\myfiles\\postdoc\\Fire\\code\\Burn_Area_Mapping\\src\\notebooks\\sentinel2.gif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4224f7e37c4da58e41b637e987cd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timelapse = geemap.sentinel2_timelapse(\n",
    "    event.geometry().bounds().buffer(5000),\n",
    "    out_gif='sentinel2.gif',\n",
    "    start_year= year,\n",
    "    end_year= year,\n",
    "    start_date= start_date,\n",
    "    end_date= end_date,\n",
    "    frequency='week',\n",
    "    bands=['SWIR2','NIR', 'Red'],#nir, swir2, gr\n",
    "    frames_per_second=1,\n",
    "    title='Sentinel-2 Timelapse',\n",
    "    cloud_pct = 30\n",
    ")\n",
    "geemap.show_image(timelapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL...\n",
      "Downloading GIF image from https://earthengine.googleapis.com/v1/projects/earthengine-legacy/videoThumbnails/81c7d31fc1f44fff27e839244c250f4a-afaf3f9ad93a54185de5dfeca5a701c0:getPixels\n",
      "Please wait ...\n",
      "The GIF image has been saved to: c:\\Users\\coach\\myfiles\\postdoc\\Fire\\code\\Burn_Area_Mapping\\src\\notebooks\\landsat.gif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cdd033ebcf442798fd9aa12e2f19ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timelapse = geemap.landsat_timelapse(\n",
    "    event.geometry().bounds().buffer(5000),\n",
    "    out_gif='landsat.gif',\n",
    "    start_year= year,\n",
    "    end_year= year,\n",
    "    start_date= start_date,\n",
    "    end_date= end_date,\n",
    "    frequency='month',\n",
    "    bands=['SWIR2','NIR', 'Red'],#nir, swir2, gr\n",
    "    frames_per_second=1,\n",
    "    title='Landsat-8 Timelapse',\n",
    ")\n",
    "geemap.show_image(timelapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erthy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
